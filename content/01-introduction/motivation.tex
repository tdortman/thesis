\section{Motivation}
\label{sec:intro:motivation}

\subsection{Problem Statement}
\label{sec:intro:problem}

In the era of big data, the ability to perform high-speed set membership queries is a fundamental requirement for applications ranging from network traffic analysis \cite{bloom-network} to large-scale distributed systems. Determining whether an element belongs to a massive set is a frequent and performance-critical operation. While exact data structures provide definitive answers, their memory footprint and computational overhead render them impractical for massive datasets. This has led to the widespread adoption of probabilistic data structures, which trade a small, manageable false-positive probability for significant gains in space and time efficiency.

For years, the Bloom filter has been the standard probabilistic data structure for approximate set membership. Its primary limitation is the inability to delete elements, making it unsuitable for dynamic datasets. While there are variations like that support deletion, they incur prohibitive space overheads that often negate their practical viability. The Cuckoo filter has emerged as a powerful alternative, offering native support for deletions and often superior space efficiency, particularly at low false-positive rates.

Despite these advantages, the performance of Cuckoo filters on traditional CPU architectures can quickly become a bottleneck in high-throughput environments. The sequential nature of the insertion algorithm, which may involve displacing multiple existing items, severely limits scalability on serial processors.

This performance gap motivates the exploration of massively parallel hardware. However, porting a Cuckoo filter to a GPU is not a straightforward translation, as the algorithm's reliance on sequential eviction chains, random memory accesses, and conditional logic conflicts with the GPU's desire for massive parallelism and structured, contiguous memory access patterns. This thesis addresses these architectural mismatches by designing, implementing, and evaluating a GPU-accelerated Cuckoo filter. The core objective is to leverage the massive parallelism of modern GPUs to handle insertions, lookups, and deletions, thereby achieving a significant performance leap over existing CPU-based implementations.

\subsection{Use Cases}
\label{sec:intro:use-cases}

The demand for high-speed, dynamic set membership testing shows up across numerous domains. While CPU-based dynamic filters exist, many modern applications generate data at a rate or scale that creates a performance bottleneck, motivating the need for a massively parallel, GPU-accelerated solution. Some of the areas that could benefit from such a filter are as follows:

\begin{itemize}
  \item \textbf{High-Speed Network Security}: Threat intelligence feeds for malicious IPs, URLs, and malware signatures are updated continuously, requiring a filter that supports both insertions and deletions. In high-speed networks (100Gbps+), a CPU can be overwhelmed by the sheer volume of packets per second. A GPU-accelerated filter can process large batches of packet headers or identifiers in parallel, enabling line-rate inspection against dynamic blacklists in a way that is infeasible for CPU-based solutions \cite{packet-classification} \cite{grashofer2018towards}.

  \item \textbf{High-Throughput Caching Systems}: Caches in Content Delivery Networks (CDNs) and HTTP reverse proxies experience constant churn as items are added and evicted. A dynamic filter is essential to prevent expensive disk or network lookups for non-existent objects. When the request rate is in the millions per second, the CPU can offload these cache-presence checks to a GPU, processing them in large, parallel batches to free up cycles for handling the actual data I/O \cite{chang2008bigtable} \cite{counting-bloom}.

  \item \textbf{Large-Scale Databases and Distributed Systems}: Database systems often use filters to avoid expensive disk lookups for non-existent keys. In a distributed setting, a GPU-accelerated filter could serve as a high-performance shared resource that tracks the existence of records across multiple nodes, reducing network latency and improving overall query performance. \cite{li1995perf} \cite{mullin2002optimal}

  \item \textbf{Bioinformatics and Computational Biology}: Genomics and proteomics research involves searching for patterns or sequences within massive biological datasets. A GPU-accelerated Cuckoo filter could be used to rapidly pre-screen for the presence of specific k-mers or genetic markers before launching more computationally intensive analyses, significantly speeding up the research pipeline. \cite{gaia2019ngsreadstreatment}
\end{itemize}
