\section{Throughput Analysis}
\label{sec:eval:throughput}

This section analyses the raw throughput of the filters in millions of operations per second (MOPS). To understand the impact of the memory hierarchy, each operation is evaluated under two distinct conditions: a small filter ($n=2^{22}$, approx. 4.2 million items) that fits entirely within the L2 cache, and a large filter ($n=2^{28}$, approx. 268 million items) that resides in DRAM.

\subsection{Insertion Performance}
\label{sec:eval:throughput:insertion}
The insertion results for both memory types are presented in Figure \ref{fig:insert-perf}.

\begin{figure}[htpb]
  \centering
  \includegraphics[width=1.0\textwidth]{images/perf/insert.pdf}
  \caption{Insertion Performance for L2-resident (Top) and DRAM-resident (Bottom) filters. Left side of each plot is System A (GDDR7), Right is System B (HBM3).}
  \label{fig:insert-perf}
\end{figure}

The GPU Cuckoo filter demonstrates exceptional competitiveness, effectively bridging the gap between static and dynamic data structures. Its insertion logic, relying on random atomic compare-and-swap operations, contrasts with the simpler, linear write patterns of the Blocked Bloom filter.

\textbf{L2-Resident}: When the filter fits in cache, the Cuckoo filter achieves a significant fraction of the Blocked Bloom filter's throughput while far surpassing all other filters.

\textbf{DRAM-Resident}: For large datasets, the Cuckoo filter scales strongly with memory bandwidth. Throughput increases significantly when moving from GDDR7 to HBM3, confirming that the algorithm successfully saturates the memory bus. In contrast, the TCF and GQF show stagnant or regressive performance on the faster HBM3 system. This reveals somewhat of a "scalability wall": these filters are bound by the speed of Shared Memory (SRAM) and intra-warp coordination rather than global DRAM bandwidth. Consequently, the Cuckoo filter remains the fastest dynamic option by a wide margin.

\FloatBarrier

\subsection{Lookup Performance}
\label{sec:eval:throughput:lookup}

Query performance, shown in Figure \ref{fig:query-perf}, highlights the impact of the Cuckoo filter's bucket layout and short-circuiting capabilities.

\begin{figure}[htpb]
  \centering
  \includegraphics[width=1.0\textwidth]{images/perf/query.pdf}
  \caption{Lookup Performance for L2-resident (Top) and DRAM-resident (Bottom) filters. Left side of each plot is System A (GDDR7), Right is System B (HBM3).}
  \label{fig:query-perf}
\end{figure}

The Cuckoo filter exhibits a distinct performance profile based on the query result. Positive lookups are highly efficient: due to the large bucket size $(b=16)$, most items reside in their primary bucket, allowing the query to complete with a single memory transaction. This allows the Cuckoo filter to match or even outperform the Blocked Bloom filter when data is cached.

For negative lookups, throughput is roughly halved because the algorithm must definitively check both candidate buckets. This behaviour contrasts with the TCF, which utilizes cooperative groups to load both buckets in parallel for every query. While the TCF offers symmetric performance for positive and negative queries, its peak throughput is about an order of magnitude lower than the Cuckoo filter's. The GQF falls somewhat in the middle, benefiting from spatial locality during linear scans but failing to match the low latency of the bucketed approaches.

\FloatBarrier

\subsection{Deletion Performance}
\label{sec:eval:throughput:deletion}

Across all scenarios, the GPU Cuckoo filter maintains a distinct performance lead, though the magnitude of this advantage depends heavily on memory residency (See Figure \ref{fig:delete-perf}).

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1.0\textwidth]{images/perf/delete.pdf}
  \caption{Deletion Performance for L2-resident (Top) and DRAM-resident (Bottom) filters. Left side of each plot is System A (GDDR7), Right is System B (HBM3).}
  \label{fig:delete-perf}
\end{figure}

In the L2-resident scenario, the Cuckoo filter is orders of magnitude faster than both the TCF and GQF. The low latency of the L2 cache allows the Cuckoo filter's simple atomic operations to run at a very high speed, while the complex coordination logic of the competitors becomes a significant bottleneck.

However, in the DRAM-resident scenario, this gap narrows as global memory latency becomes the dominant factor for all implementations. On the GDDR7 system, the Cuckoo filter is approximately 67\% faster than the GQF, while on the HBM3 system, the lead extends to approximately 3.5$\times$. Despite the narrowing gap, the Cuckoo filter remains the fastest option due to fundamental algorithmic differences:

\begin{itemize}
  \item \textbf{Cuckoo Filter}: Deletion is a simple, localized atomic operation (CAS).
  \item \textbf{GQF}: Requires shifting elements within a run to maintain sorted order. While efficient in bulk, this serial operation limits peak throughput.
  \item \textbf{TCF}: Requires complex coordination within cooperative groups to update block state, which scales poorly compared to independent atomic accesses.
\end{itemize}

\FloatBarrier
