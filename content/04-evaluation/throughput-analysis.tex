\section{Throughput Analysis}
\label{sec:eval:throughput}

This section analyses the raw throughput of the filters in millions of operations per second (MOPS). To understand the impact of the memory hierarchy, each operation is evaluated under two distinct conditions: a small filter ($n=2^{22}$, approx. 4.2 million items) that fits entirely within the L2 cache, and a large filter ($n=2^{28}$, approx. 268 million items) that resides in DRAM.

\subsection{Insertion Performance}
\label{sec:eval:throughput:insertion}
The insertion results for both memory types are presented in Figure \ref{fig:insert-perf}.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1.0\textwidth]{images/perf/insert.pdf}
  \caption{Insertion Performance for L2-resident (Top) and DRAM-resident (Bottom) filters. Left side of each plot is System A (GDDR7), Right is System B (HBM3).}
  \label{fig:insert-perf}
\end{figure}

The GPU Cuckoo filter demonstrates exceptional competitiveness, effectively bridging the gap between static and dynamic data structures. Its insertion logic, relying on random atomic compare-and-swap operations, contrasts with the simpler, linear write patterns of the Blocked Bloom filter.

\textbf{L2-Resident}: When the filter fits in cache, the Cuckoo filter achieves a significant fraction of the Blocked Bloom filter's throughput while surpassing all other filters by at least an order of magnitude.

\textbf{DRAM-Resident}: For large datasets, the Cuckoo filter scales strongly with memory bandwidth. Throughput increases significantly when moving from GDDR7 to HBM3, confirming that the algorithm successfully saturates the memory bus. In contrast, the TCF and GQF show stagnant or regressive performance on the faster HBM3 system. This reveals somewhat of a "scalability wall": these filters are bound by the speed of Shared Memory (SRAM) and intra-warp coordination rather than global DRAM bandwidth. Consequently, the Cuckoo filter remains the fastest dynamic option by a wide margin.

\FloatBarrier

\subsection{Lookup Performance}
\label{sec:eval:throughput:lookup}

Query performance, shown in Figure \ref{fig:query-perf}, highlights the impact of the Cuckoo filter's bucket layout and short-circuiting capabilities.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1.0\textwidth]{images/perf/query.pdf}
  \caption{Lookup Performance for L2-resident (Top) and DRAM-resident (Bottom) filters. Left side of each plot is System A (GDDR7), Right is System B (HBM3).}
  \label{fig:query-perf}
\end{figure}

The Cuckoo filter exhibits a distinct performance profile based on the query result. Positive lookups are highly efficient: due to the large bucket size $(b=16)$, most items reside in their primary bucket, allowing the query to complete with a single memory transaction. This allows the Cuckoo filter to match or even outperform the Blocked Bloom filter when data is cached.

For negative lookups, throughput is roughly halved because the algorithm must definitively check both candidate buckets. This behaviour contrasts with the TCF, which utilizes cooperative groups to load both buckets in parallel for every query. While the TCF offers symmetric performance for positive and negative queries, its peak throughput is about an order of magnitude lower than the Cuckoo filter's. The GQF falls somewhat in the middle, benefiting from spatial locality during linear scans but failing to match the low latency of the bucketed approaches.

\FloatBarrier

\subsection{Deletion Performance}
\label{sec:eval:throughput:deletion}

Deletion performance (Figure \ref{fig:delete-perf}) shows the most significant advantage of the GPU Cuckoo filter.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=1.0\textwidth]{images/perf/delete.pdf}
  \caption{Deletion Performance for L2-resident (Top) and DRAM-resident (Bottom) filters. Left side of each plot is System A (GDDR7), Right is System B (HBM3).}
  \label{fig:delete-perf}
\end{figure}

Across both memory types and hardware architectures, the Cuckoo filter is orders of magnitude faster than its competitors. This massive gap stems from fundamental algorithmic differences:

\begin{itemize}
  \item \textbf{Cuckoo Filter}: Deletion is a simple, localized atomic operation (CAS).
  \item \textbf{GQF}: Requires shifting elements within a run to maintain sorted order, a serial operation that maps poorly to GPUs.
  \item \textbf{TCF}: Requires complex coordination within cooperative groups to update block state.
\end{itemize}

These complex maintenance operations in the GQF and TCF interact poorly with memory latency, creating a severe bottleneck that no amount of extra bandwidth (HBM3) or cache speed (L2 residency) can overcome.

\FloatBarrier
