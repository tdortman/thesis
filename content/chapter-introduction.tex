% !TEX root = ../my-thesis.tex
%
\chapter{Introduction}
\label{sec:intro}

\section{Motivation}
\label{sec:intro:motivation}

\subsection{Problem Statement}
\label{sec:intro:problem}

In the era of big data, the ability to perform high-speed set membership queries is a fundamental requirement for applications ranging from network traffic analysis \cite{bloom-network} to large-scale distributed systems. Determining whether an element belongs to a massive set is a frequent and performance-critical operation. While exact data structures provide definitive answers, their memory footprint and computational overhead render them impractical for massive datasets. This has led to the widespread adoption of probabilistic data structures, which trade a small, manageable false-positive probability for significant gains in space and time efficiency.

For years, the Bloom filter has been the standard probabilistic data structure for approximate set membership. However, its primary limitation is the inability to delete elements, making it unsuitable for dynamic datasets. While variations like the \textit{Counting Bloom filter} \cite{counting-bloom} support deletion, they incur prohibitive space overheads that often negate their practical viability. The Cuckoo filter has emerged as a powerful alternative, offering native support for deletions and often superior space efficiency, particularly at low false-positive rates.

Despite these advantages, the performance of Cuckoo filters on traditional CPU architectures can become a bottleneck in high-throughput environments. The sequential nature of the insertion algorithm, which may involve displacing multiple existing items, severely limits scalability on serial processors.

This performance gap motivates the exploration of massively parallel hardware. However, porting a Cuckoo filter to a GPU is not a straightforward translation, as the algorithm's reliance on sequential eviction chains, random memory accesses, and conditional logic conflicts with the GPU's requirement for massive parallelism and structured, contiguous memory access patterns. This thesis addresses these architectural mismatches by designing, implementing, and evaluating a GPU-accelerated Cuckoo filter. The core objective is to leverage the massive parallelism of modern GPUs to handle insertions, lookups, and deletions concurrently, thereby achieving a significant performance leap over existing CPU-based implementations.

\subsection{Use Cases}
\label{sec:intro:use-cases}

The demand for high-speed, dynamic set membership testing shows up across numerous domains. While CPU-based dynamic filters exist, many modern applications generate data at a rate or scale that creates a performance bottleneck, motivating the need for a massively parallel, GPU-accelerated solution. Such a filter would provide substantial benefits in the following areas and more:

\begin{itemize}
  \item \textbf{High-Speed Network Security}: Threat intelligence feeds for malicious IPs, URLs, and malware signatures are updated continuously, requiring a filter that supports both insertions and deletions. In high-speed networks (100Gbps+), a CPU can be overwhelmed by the sheer volume of packets per second. A GPU-accelerated filter can process large batches of packet headers or identifiers in parallel, enabling line-rate inspection against dynamic blacklists in a way that is infeasible for CPU-based solutions \cite{packet-classification} \cite{grashofer2018towards}.

  \item \textbf{High-Throughput Caching Systems}: Caches in Content Delivery Networks (CDNs) and HTTP reverse proxies experience constant churn as items are added and evicted. A dynamic filter is essential to prevent expensive disk or network lookups for non-existent objects. When the request rate is in the millions per second, the CPU can offload these cache-presence checks to a GPU, processing them in large, parallel batches to free up cycles for handling the actual data I/O \cite{chang2008bigtable} \cite{counting-bloom}.

  \item \textbf{Large-Scale Databases and Distributed Systems}: Database systems often use filters to avoid expensive disk lookups for non-existent keys. In a distributed setting, a GPU-accelerated filter could serve as a high-performance shared resource that tracks the existence of records across multiple nodes, reducing network latency and improving overall query performance. \cite{li1995perf} \cite{mullin2002optimal}

  \item \textbf{Bioinformatics and Computational Biology}: Genomics and proteomics research involves searching for patterns or sequences within massive biological datasets. A GPU-accelerated Cuckoo filter could be used to rapidly pre-screen for the presence of specific k-mers or genetic markers before launching more computationally intensive analyses, significantly speeding up the research pipeline. \cite{gaia2019ngsreadstreatment}
\end{itemize}

\section{Contributions}
\label{sec:intro:contributions}

This thesis presents a comprehensive study on accelerating probabilistic data structures using GPUs. The main contributions of this work are as follows:

\begin{itemize}
  \item \textbf{A Novel GPU-Accelerated Cuckoo Filter Design}: The design and implementation of a parallel Cuckoo filter supporting insertion, lookup, and deletion are presented. The implementation introduces a lock-free, atomic-based mechanism to handle the "cuckoo" eviction process safely within a massively parallel environment, addressing the challenge of managing race conditions without sacrificing throughput.

  \item \textbf{Advanced Optimization Techniques}: Several optimization strategies are explored and evaluated to maximize occupancy and memory bandwidth. These include a sorted-insertion algorithm to improve memory locality and a modified eviction strategy designed to reduce eviction chain lengths at high load factors.

  \item \textbf{System-Level Integration Extensions}: Moving beyond a standalone kernel, two extensions are contributed to facilitate real-world adoption. First, an Inter-Process Communication (IPC) wrapper is developed to enable zero-copy, low-latency sharing of the filter between processes. Second, a multi-GPU implementation is provided that transparently partitions data across multiple devices using NCCL, allowing the filter to scale beyond the memory limits of a single card.

  \item \textbf{Comprehensive Evaluation}: A rigorous performance analysis is conducted comparing the GPU Cuckoo filter against CPU baselines and a GPU Blocked Bloom filter. The results demonstrate that the implementation achieves competitive throughput—reaching within 83\% of the read-only Blocked Bloom filter's performance—while offering the critical advantage of dynamic deletion support.
\end{itemize}

\section{Thesis Structure}
\label{sec:intro:structure}

\textbf{Chapter \ref{sec:related}} \\[0.2em]
\blindtext

\textbf{Chapter \ref{sec:system}} \\[0.2em]
\blindtext

\textbf{Chapter \ref{sec:concepts}} \\[0.2em]
\blindtext

\textbf{Chapter \ref{sec:concepts}} \\[0.2em]
\blindtext

\textbf{Chapter \ref{sec:conclusion}} \\[0.2em]
\blindtext
