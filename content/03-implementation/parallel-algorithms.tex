\section{Parallel Algorithms}
\label{sec:implementation:parallel-algorithms}

The core of this thesis is the design of parallel algorithms for the Cuckoo filter's primary operations: insertion, lookup, and deletion. These algorithms are designed to be launched as CUDA kernels, where many threads cooperate to process batches of items simultaneously.

\subsection{Insertion}
\label{sec:implementation:insertion}

The parallel insertion algorithm is designed to handle a large batch of items in parallel, with each CUDA thread being responsible for inserting a single item. The process for each thread is as follows:

\begin{enumerate}
  \item \textbf{Hashing and Key Generation}: Each item is first hashed into a 64-bit value using the xxHash64 algorithm, chosen for its high speed and excellent statistical properties. This hash is then split: the upper 32 bits are used to derive the item's fingerprint, while the lower 32 bits are used as the basis for its primary bucket index. A crucial initial finding was that using the same bits for both the fingerprint and the primary index led to a high probability of identical fingerprints clustering in the same buckets, causing a severe degradation in performance. Thus, distinct parts of the hash are used for each. The alternate bucket index is then calculated using the partial-key cuckoo hashing scheme, which is described in detail in Section \ref{sec:background:cuckoo-filter}.

  \item \textbf{Direct Insertion Attempt}: The thread checks the two candidate buckets. Instead of iterating through slots sequentially, the algorithm loads the bucket as a sequence of 64-bit words. It utilizes a bitwise SWAR algorithm (specifically, the standard "zero-byte detection" trick) \cite{bit-twiddling-hacks} to generate a mask of all empty slots in the word simultaneously. The index of the first empty slot is determined using the hardware intrinsic \texttt{\_\_ffsll} (Find First Set). If a slot is found, an atomic Compare-And-Swap (CAS) is attempted to transition the word from its old state to a new state containing the inserted fingerprint.

  \item \textbf{Eviction Process}: If both candidate buckets are full, the thread initiates the cuckoo process. It randomly selects one of the two buckets and a random occupied slot within it. It then atomically replaces the fingerprint (\texttt{tag\_old}) in that slot with its own fingerprint (\texttt{tag\_new}). The evicted fingerprint, \texttt{tag\_old}, now becomes the item that the thread must insert. The thread calculates \texttt{tag\_old}'s alternate bucket and continues this process in a loop.

  \item \textbf{Termination}: The eviction loop continues until either an empty slot is found or a predefined limit on the number of evictions is reached, at which point the insertion is reported as a failure.

\end{enumerate}

To maintain an accurate count of the total items in the filter without creating a bottleneck on a single atomic counter, a hierarchical reduction is employed. Each thread that successfully inserts an item contributes a +1. These values are first summed efficiently at the warp level using shuffle instructions, then aggregated at the block level using shared memory, and finally, a single atomic addition per block is performed on the global counter in device memory.

% tex-fmt: off
\begin{algorithm}[htbp]
  \caption{Parallel Insertion}
  \label{alg:parallel-insertion}
  \begin{algorithmic}[1]
    \Function{Insert}{key}
      \State $h \gets \mathrm{hash}(\text{key})$
      \State $fp \gets \mathrm{fingerprint}(h)$
      \State $i_1 \gets \mathrm{primary\_index}(h)$
      \State $i_2 \gets \mathrm{alternate\_index}(i_1, fp)$

      \LComment{Phase 1: Try direct insertion using SWAR}
      \If{\Call{TryInsert}{$i_1$, $fp$} \textbf{or} \Call{TryInsert}{$i_2$, $fp$}}
        \State \textbf{return} \texttt{Success}
      \EndIf

      \LComment{Phase 2: Eviction Chain}
      \State $b \gets$ randomly pick $i_1$ or $i_2$
      \State $\text{tag} \gets fp$

      \For{$n = 1$ \textbf{to} \text{maxEvictions}}
        \State $s \gets$ random slot index in bucket $b$
        \LComment{Atomically swap current tag with new tag}
        \State $\text{tag} \gets \text{AtomicExchange}(\text{bucket}[b].\text{slot}[s],\ \text{tag})$
        \State $b \gets \text{alternate\_index}(b, \text{tag})$

        \If{\Call{TryInsert}{bucket $b$, \text{tag}}}
          \State \textbf{return} \texttt{Success}
        \EndIf
      \EndFor

      \LComment{Table too full}
      \LComment{Caller will have to rebuild}
      \State \textbf{return} \texttt{Failure}
    \EndFunction
    \Statex
    \Function{TryInsert}{bucket, tag}
      \For{each \texttt{word} in \texttt{bucket}}
        \While{\texttt{word} has empty slots}
           \State \texttt{slot} $\gets$ \Call{FindNextEmpty}{\texttt{word}}
           \If{\text{AtomicCAS}(\texttt{word}, \texttt{EMPTY} $\to$ \texttt{tag} at \texttt{slot})}
             \State \textbf{return} \texttt{True}
           \EndIf
           \LComment{Reload and re-check if CAS failed}
           \State Reload \texttt{word}
        \EndWhile
      \EndFor
      \State \textbf{return} \texttt{False}
    \EndFunction
  \end{algorithmic}
\end{algorithm}
% tex-fmt: on

\subsection{Lookup}
\label{sec:implementation:lookup}

The parallel lookup algorithm is similar to insertion but is a read-only operation, allowing for more aggressive memory access optimizations. Each thread is assigned an item to look for.

The thread calculates the item's fingerprint and its two candidate bucket indices, just as in the insertion process. However, instead of iterating through slots sequentially or using a linear probe, the algorithm retrieves the bucket contents in chunks aligned to the machine word size. Despite the ability to use two threads per item to check both buckets in parallel, this was found to be slower in every tested case, so a single thread checks both buckets sequentially.

The key optimization in the lookup kernel is the combination of vectorized, non-atomic memory loads with SWAR (SIMD Within A Register) comparisons. Since no other kernel is writing to the filter during a lookup, thread safety is not a concern. Modern GPU hardware can load 128 bits (16 bytes) in a single instruction. The kernel leverages this to load two 64-bit words into registers simultaneously. Once loaded, the query fingerprint is broadcast across a 64-bit pattern and XORed with the bucket data. A bitwise zero-detection mask is then applied to the result. This allows the thread to compare multiple fingerprints (e.g., up to 8 with 16-bit tags) against the query tag using only constant-time arithmetic operations, eliminating the branching overhead of a linear search loop.

% tex-fmt: off
\begin{algorithm}[htbp]
  \caption{Parallel Lookup}
  \label{alg:parallel-lookup}
  \begin{algorithmic}[1]
    \Function{Contains}{key}
      \State $h \gets \mathrm{hash}(\text{key})$
      \State $fp \gets \mathrm{fingerprint}(h)$
      \State $i_1 \gets \mathrm{primary\_index}(h)$
      \State $i_2 \gets \mathrm{alternate\_index}(i_1, fp)$

      \LComment{Check both buckets (read-only, no locking needed)}
      \State \textbf{return} \Call{Find}{$i_1$, $fp$} \textbf{or} \Call{Find}{$i_2$, $fp$}
    \EndFunction
    \Statex
    \Function{Find}{bucket, tag}
      \State \texttt{pattern} $\gets$ \Call{BroadcastTag}{tag}

      \LComment{Load bucket in 128-bit chunks (vectorized load)}
      \For{$i = 0$ \textbf{to} $\text{wordCount} - 1$ \textbf{step} 2}
        \State $w_1, w_2 \gets$ \Call{LoadWords}{bucket, $i$}

        \LComment{Use SWAR to check for matches in parallel}
        \If{\Call{HasZeroByte}{$w_1 \oplus \texttt{pattern}$} \textbf{or} \Call{HasZeroByte}{$w_2 \oplus \texttt{pattern}$}}
            \State \textbf{return} \texttt{Success}
        \EndIf
      \EndFor
      \State \textbf{return} \texttt{Failure}
    \EndFunction
  \end{algorithmic}
\end{algorithm}
% tex-fmt: on
\subsection{Deletion}
\label{sec:implementation:deletion}

The parallel deletion algorithm leverages SWAR to locate and remove items efficiently while maintaining data integrity. Similar to insertion, the algorithm iterates through the bucket in 64-bit word chunks.

To locate the target fingerprint, the thread broadcasts the target tag across a register and performs an XOR operation with the loaded word. The result is passed through the zero-byte detection formula. If the resulting mask is non-zero, it indicates that one or more slots within the word contain the target tag. The precise index of the first matching slot is extracted using the \texttt{\_\_ffsll} intrinsic.

Once a match is found, the thread calculates a new 64-bit value where the target slot is set to \texttt{EMPTY} (zero), while preserving all other slots. It then attempts to commit this change using an atomic Compare-And-Swap (CAS) on the entire word.

The CAS operation is critical here:

\begin{itemize}
  \item \textbf{Success}: If the CAS succeeds, the item has been removed and the kernel returns successfully.

  \item \textbf{Failure}: If the CAS fails, it implies another thread modified the word (e.g., inserted or deleted a neighbour) in the meantime. The thread must reload the current value of the word and re-evaluate the SWAR logic. This retry loop ensures that the thread never accidentally overwrites a concurrent modification.
\end{itemize}

Each deletion attempt proceeds until an entry has been successfully removed, or both buckets have been fully examined. This approach ensures the operation is handled independently and correctly, even when duplicate fingerprints exist. The success or failure of each operation can be optionally reported back to the host via a provided bit-vector. Similarly to how it is done after insertion, a hierarchical reduction on the success values is used to minimize contention when decrementing the atomic counter that holds the number of occupied slots in the filter.

% tex-fmt: off
\begin{algorithm}[htbp]
  \caption{Parallel Deletion}
  \label{alg:parallel-deletion}
  \begin{algorithmic}[1]
    \Function{Remove}{key}
      \State $h \gets \mathrm{hash}(\text{key})$
      \State $fp \gets \mathrm{fingerprint}(h)$
      \State $i_1 \gets \mathrm{primary\_index}(h)$
      \State $i_2 \gets \mathrm{alternate\_index}(i_1, fp)$

      \LComment{Attempt to remove from either valid location}
      \State \textbf{return} \Call{Remove}{$i_1$, $fp$} \textbf{or} \Call{Remove}{$i_2$, $fp$}
    \EndFunction
    \Statex
    \Function{Remove}{bucket, targetTag}
      \For{each \texttt{word} in \texttt{bucket}}
        \State \texttt{mask} $\gets$ \Call{SWAR\_Match}{\texttt{word}, \texttt{targetTag}}

        \While{\texttt{mask} is not 0}
           \State \texttt{slot} $\gets$ \Call{FindFirstSet}{\texttt{mask}}

           \LComment{Attempt to atomically set specific slot to EMPTY}
           \If{\text{AtomicCAS}(\texttt{word}, \texttt{targetTag} $\to$ \texttt{EMPTY} at \texttt{slot})}
             \State \textbf{return} \texttt{Success}
           \EndIf

           \LComment{Reload and re-check if CAS failed}
           \State Reload \texttt{word}
           \State \texttt{mask} $\gets$ \Call{SWAR\_Match}{\texttt{word}, \texttt{targetTag}}
        \EndWhile
      \EndFor
      \State \textbf{return} \texttt{Failure}
    \EndFunction
  \end{algorithmic}
\end{algorithm}
% tex-fmt: on

\FloatBarrier